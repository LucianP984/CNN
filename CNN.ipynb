{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":23812,"sourceType":"datasetVersion","datasetId":17810}],"dockerImageVersionId":31041,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"\"\"\"\nimports all necessary libraries for data handling, deep learning, visualization, and xai (explainable ai).\n os: for file and directory operations\n numpy/pandas: for numerical and tabular data processing\n matplotlib/seaborn: for data visualization\n tensorflow/keras: for building and training deep learning models\n sklearn: for evaluation metrics\n lime/shap: for model interpretability (xai)\n cv2: for image processing\n warnings: to suppress unnecessary warnings\n\"\"\"\nimport os\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport tensorflow as tf\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.models import Sequential, Model\nfrom tensorflow.keras.applications import VGG16\nfrom tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\nfrom tensorflow.keras import backend as K\nfrom sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc, roc_auc_score\nfrom sklearn.metrics import precision_recall_curve, average_precision_score, f1_score\nimport matplotlib.cm as cm\n\nfrom tensorflow.keras.layers import (\n    Conv2D, MaxPooling2D, Flatten, Dense, Dropout,\n    BatchNormalization, GlobalAveragePooling2D, Activation,\n    Input, Add, Lambda, SeparableConv2D, SpatialDropout2D\n)\nfrom tensorflow.keras.regularizers import l2\nimport tensorflow.keras.backend as K\n\n# XAI Libraries\nfrom lime import lime_image\nfrom skimage.segmentation import mark_boundaries\nimport shap\nimport cv2\nimport warnings\nwarnings.filterwarnings('ignore')\n\n\"\"\"\nsets random seeds for numpy and tensorflow to ensure reproducibility.\nnp.random.seed(42): fixes numpy's random number generation\ntf.random.set_seed(42): fixes tensorflow's random initialization\nthis helps in getting consistent results across multiple runs.\n\"\"\"\nnp.random.seed(42)\ntf.random.set_seed(42)\n\n\"\"\"\nchecks if the dataset directory exists and falls back to a local path if needed.\nfirst checks the kaggle path (/kaggle/input/...)\nif not found, tries a local path ('./chest_xray')\nraises an error if neither path exists.\n\"\"\"\ndata_dir = '/kaggle/input/chest-xray-pneumonia/chest_xray'\nprint(\"TensorFlow Version:\", tf.__version__)\nprint(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\ngpus = tf.config.list_physical_devices('GPU')\nif gpus:\n  try:\n    for gpu in gpus:\n      tf.config.experimental.set_memory_growth(gpu, True)\n    logical_gpus = tf.config.list_logical_devices('GPU')\n    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n  except RuntimeError as e:\n    print(e)\nelse:\n    print(\"No GPU detected. Training will run on CPU (which will be slow).\")\n\"\"\"\ndefines train, test, and validation directories and checks their existence.\ntrain_dir: path to training data\ntest_dir: path to testing data\nval_dir: path to validation data\nraises an error if any of these directories are missing.\n\"\"\"\nif not os.path.isdir(data_dir):\n    # Fallback for local execution if Kaggle path not found\n    print(f\"Kaggle directory {data_dir} not found. Trying local path './chest_xray'.\")\n    data_dir = './chest_xray' # Example local path\n    if not os.path.isdir(data_dir):\n        raise FileNotFoundError(f\"Dataset directory not found at: {data_dir} or the Kaggle path. Please ensure the path is correct and the dataset is downloaded/extracted.\")\n\ntrain_dir = os.path.join(data_dir, 'train')\ntest_dir = os.path.join(data_dir, 'test')\nval_dir = os.path.join(data_dir, 'val')\n\n# Check subdirectories\nif not os.path.isdir(train_dir) or not os.path.isdir(test_dir) or not os.path.isdir(val_dir):\n     raise FileNotFoundError(f\"Train, test, or val directory not found within {data_dir}. Check the dataset structure.\")\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-05-15T09:00:22.137472Z","iopub.execute_input":"2025-05-15T09:00:22.138040Z","execution_failed":"2025-05-15T09:00:30.085Z"}},"outputs":[{"name":"stderr","text":"2025-05-15 09:00:24.543173: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1747299624.724218      35 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1747299624.774283      35 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"print(\"TensorFlow Version:\", tf.__version__)\nprint(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\ngpus = tf.config.list_physical_devices('GPU')\nif gpus:\n  try:\n    for gpu in gpus:\n      tf.config.experimental.set_memory_growth(gpu, True)\n    logical_gpus = tf.config.list_logical_devices('GPU')\n    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n  except RuntimeError as e:\n    print(e)\nelse:\n    print(\"No GPU detected. Training will run on CPU (which will be slow).\")\n","metadata":{"trusted":true,"execution":{"execution_failed":"2025-05-15T09:00:30.085Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 1. Dataset Exploration\ndef explore_dataset():\n    \"\"\"\n    explores and visualizes the chest x-ray dataset distribution and characteristics.\n    performs the following analyses:\n    counts images in each class (normal/pneumonia) across train/val/test sets\n    calculates class imbalance ratios\n    plots class distribution bar charts\n    displays sample normal and pneumonia x-ray images\n    analyzes image dimensions in the dataset\n\n    handles potential file access errors gracefully with try-except blocks.\n\n    returns:\n        dict: a dictionary containing image counts for each class and dataset split\n              format: {\n                  'train': {'normal': int, 'pneumonia': int},\n                  'val': {'normal': int, 'pneumonia': int},\n                  'test': {'normal': int, 'pneumonia': int}\n              }\n\n    raises:\n        FileNotFoundError: if required subdirectories are missing\n        other exceptions: caught and printed without stopping execution\n    \"\"\"\n    try:\n        normal_train = len(os.listdir(os.path.join(train_dir, 'NORMAL')))\n        pneumonia_train = len(os.listdir(os.path.join(train_dir, 'PNEUMONIA')))\n\n        normal_val = len(os.listdir(os.path.join(val_dir, 'NORMAL')))\n        pneumonia_val = len(os.listdir(os.path.join(val_dir, 'PNEUMONIA')))\n\n        normal_test = len(os.listdir(os.path.join(test_dir, 'NORMAL')))\n        pneumonia_test = len(os.listdir(os.path.join(test_dir, 'PNEUMONIA')))\n    except FileNotFoundError as e:\n        print(f\"Error accessing dataset files: {e}\")\n        print(\"Please ensure the 'NORMAL' and 'PNEUMONIA' subdirectories exist in train, test, and val folders.\")\n        raise\n\n    print(\"Dataset Distribution:\")\n    ratio_train = pneumonia_train / normal_train if normal_train > 0 else float('inf')\n    ratio_val = pneumonia_val / normal_val if normal_val > 0 else float('inf')\n    ratio_test = pneumonia_test / normal_test if normal_test > 0 else float('inf')\n\n    print(f\"Training: Normal={normal_train}, Pneumonia={pneumonia_train}, Ratio=1:{ratio_train:.2f}\")\n    print(f\"Validation: Normal={normal_val}, Pneumonia={pneumonia_val}, Ratio=1:{ratio_val:.2f}\")\n    print(f\"Testing: Normal={normal_test}, Pneumonia={pneumonia_test}, Ratio=1:{ratio_test:.2f}\")\n\"\"\"\n    creates visualization of class distribution across train and test sets.\n    generates a 2-panel bar plot comparing normal vs pneumonia cases\n    uses skyblue for normal cases, salmon for pneumonia cases\n    adds grid lines for better readability\n    saves the plot as 'class_distribution.png'\n    \"\"\"\n    plt.figure(figsize=(12, 5))\n    plt.subplot(1, 2, 1)\n    plt.bar(['Normal', 'Pneumonia'], [normal_train, pneumonia_train], color=['skyblue', 'salmon'])\n    plt.title('Training Set Distribution')\n    plt.ylabel('Number of Images')\n    plt.grid(axis='y', alpha=0.3)\n    plt.subplot(1, 2, 2)\n    plt.bar(['Normal', 'Pneumonia'], [normal_test, pneumonia_test], color=['skyblue', 'salmon'])\n    plt.title('Testing Set Distribution')\n    plt.ylabel('Number of Images')\n    plt.grid(axis='y', alpha=0.3)\n    plt.tight_layout()\n    plt.savefig('class_distribution.png')\n    plt.show()\n\n    plt.figure(figsize=(12, 6))\n    try:\n        normal_files = os.listdir(os.path.join(train_dir, 'NORMAL'))\n        if not normal_files: raise FileNotFoundError(\"No files found in training NORMAL directory\")\n        normal_img_path = os.path.join(train_dir, 'NORMAL', normal_files[0])\n        normal_img = plt.imread(normal_img_path)\n\n        pneumonia_files = os.listdir(os.path.join(train_dir, 'PNEUMONIA'))\n        if not pneumonia_files: raise FileNotFoundError(\"No files found in training PNEUMONIA directory\")\n        pneumonia_img_path = os.path.join(train_dir, 'PNEUMONIA', pneumonia_files[0])\n        pneumonia_img = plt.imread(pneumonia_img_path)\n\n        plt.subplot(1, 2, 1)\n        plt.imshow(normal_img, cmap='gray')\n        plt.title('Normal')\n        plt.axis('off')\n        plt.subplot(1, 2, 2)\n        plt.imshow(pneumonia_img, cmap='gray')\n        plt.title('Pneumonia')\n        plt.axis('off')\n        plt.tight_layout()\n        plt.savefig('sample_images.png')\n        plt.show()\n    except FileNotFoundError as e:\n        print(f\"Could not load sample images: {e}\")\n    except Exception as e:\n        print(f\"An error occurred displaying sample images: {e}\")\n    \"\"\"\n    analyzes image dimensions in the dataset.\n    checks the shapes of the first 100 images in each class\n    prints unique shapes found in each class\n    helps identify if resizing/normalization will be needed\n    \"\"\"\n    try:\n        normal_sizes = []\n        pneumonia_sizes = []\n        for img_file in os.listdir(os.path.join(train_dir, 'NORMAL'))[:100]:\n            img = plt.imread(os.path.join(train_dir, 'NORMAL', img_file))\n            normal_sizes.append(img.shape)\n        for img_file in os.listdir(os.path.join(train_dir, 'PNEUMONIA'))[:100]:\n            img = plt.imread(os.path.join(train_dir, 'PNEUMONIA', img_file))\n            pneumonia_sizes.append(img.shape)\n        print(\"\\nImage Size Distribution (Sample):\")\n        print(\"Normal images (shapes):\", set(normal_sizes))\n        print(\"Pneumonia images (shapes):\", set(pneumonia_sizes))\n    except Exception as e:\n        print(f\"Could not analyze image sizes: {e}\")\n\n    return {\n        'train': {'normal': normal_train, 'pneumonia': pneumonia_train},\n        'val': {'normal': normal_val, 'pneumonia': pneumonia_val},\n        'test': {'normal': normal_test, 'pneumonia': pneumonia_test}\n    }","metadata":{"trusted":true,"execution":{"execution_failed":"2025-05-15T09:00:30.085Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# # 2. Data Preprocessing\ndef create_data_generators(img_size=224, batch_size=32, validation_split=0.2):\n    \"\"\"\n    creates and configures data generators for training, validation, and testing.\n    applies data augmentation to training set and maintains separate validation/test sets.\n    \n    args:\n        img_size (int): target dimensions for images (square, default 224x224)\n        batch_size (int): number of images per batch (default 32)\n        validation_split (float): fraction of training data to use for validation (default 0.2)\n    \n    returns:\n        tuple: contains three keras.preprocessing.image.DirectoryIterator objects:\n            - train_gen: training data generator with augmentation\n            - val_gen: validation data generator\n            - test_gen: test data generator\n    \n    raises:\n        exception: if directory structure is invalid or images can't be loaded\n    \"\"\"\n    \n    \"\"\"\n    configures the training data generator with extensive augmentation.\n    transformations include:\n    normalization (rescale to 0-1 range)\n    random rotations (up to 15 degrees)\n    small width/height shifts (10% of image size)\n    slight shearing and zooming (10% range)\n    horizontal flipping\n    brightness adjustment (±10%)\n    automatic splitting into train/validation sets\n    \"\"\"\n    train_datagen = ImageDataGenerator(\n        rescale=1./255,\n        rotation_range=15,\n        width_shift_range=0.1,\n        height_shift_range=0.1,\n        shear_range=0.1,\n        zoom_range=0.1,\n        horizontal_flip=True,\n        fill_mode='nearest',\n        brightness_range=[0.9, 1.1],\n        validation_split=validation_split  # This will split the training data\n    )\n    \"\"\"\n    configures a simpler generator for validation and testing.\n    only applies normalization since we don't want to augment these sets.\n    \"\"\"\n    val_test_datagen = ImageDataGenerator(rescale=1./255)\n\n    try:\n        \"\"\"\n        creates the main training generator:\n        uses 80% of training data (1-validation_split)\n        shuffles the samples for better training\n        converts images to rgb (3 channels)\n        uses binary classification mode (normal=0, pneumonia=1)\n        \"\"\"\n        train_gen = train_datagen.flow_from_directory(\n            train_dir,\n            target_size=(img_size, img_size),\n            batch_size=batch_size,\n            class_mode='binary',\n            color_mode='rgb',\n            shuffle=True,\n            subset='training'  # This is the key change\n        )\n        \n        \"\"\"\n        creates validation generator:\n        uses 20% of training data (validation_split)\n        maintains original order (no shuffling)\n        same image processing as training (minus augmentation)\n        \"\"\"\n        val_gen = train_datagen.flow_from_directory(\n            train_dir,\n            target_size=(img_size, img_size),\n            batch_size=batch_size,\n            class_mode='binary',\n            color_mode='rgb',\n            shuffle=False,\n            subset='validation'  # This is the key change\n        )\n        \n        \"\"\"\n        creates test generator:\n        uses the original held-out test set\n        no augmentation or shuffling\n        same preprocessing as validation\n        \"\"\"\n        test_gen = val_test_datagen.flow_from_directory(\n            test_dir,\n            target_size=(img_size, img_size),\n            batch_size=batch_size,\n            class_mode='binary',\n            color_mode='rgb',\n            shuffle=False\n        )\n        \n        print(f\"Found {train_gen.samples} images for training ({1-validation_split:.0%} of training set)\")\n        print(f\"Found {val_gen.samples} images for validation ({validation_split:.0%} of training set)\")\n        print(f\"Found {test_gen.samples} images for testing\")\n        \n    except Exception as e:\n        print(f\"Error creating data generators: {e}\")\n        raise\n    return train_gen, val_gen, test_gen","metadata":{"trusted":true,"execution":{"execution_failed":"2025-05-15T09:00:30.085Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 3. Calculate Class Weights\ndef calculate_class_weights(dataset_info):\n    def calculate_class_weights(dataset_info):\n    \"\"\"\n    calculates class weights to address dataset imbalance during model training.\n    weights are inversely proportional to class frequencies to help the model learn\n    from underrepresented classes more effectively.\n\n    args:\n        dataset_info (dict): dictionary containing class counts from explore_dataset()\n                            format: {\n                                'train': {'normal': int, 'pneumonia': int},\n                                'val': {...},\n                                'test': {...}\n                            }\n\n    returns:\n        dict: class weights dictionary in format {0: weight_normal, 1: weight_pneumonia}\n              returns equal weights (1.0) if either class has zero samples\n\n    note:\n        weight calculation formula: weight = total_samples / (num_classes * class_count)\n        this gives more weight to underrepresented classes during training\n    \"\"\"\n    normal_count = dataset_info['train']['normal']\n    pneumonia_count = dataset_info['train']['pneumonia']\n    if normal_count == 0 or pneumonia_count == 0:\n        print(\"Warning: One class has zero samples in the training set. Cannot compute weights.\")\n        return {0: 1.0, 1: 1.0}\n    total = normal_count + pneumonia_count\n    weight_normal = total / (2 * normal_count)\n    weight_pneumonia = total / (2 * pneumonia_count)\n    class_weights = {0: weight_normal, 1: weight_pneumonia}\n    print(f\"Calculated Class weights: Normal (0)={weight_normal:.2f}, Pneumonia (1)={weight_pneumonia:.2f}\")\n    return class_weights\n\n# 4. Focal Loss\ndef focal_loss(gamma=2., alpha=.25):\n    \"\"\"\n    implements focal loss function for handling severe class imbalance.\n    focal loss down-weights easy examples and focuses training on hard misclassified examples.\n\n    args:\n        gamma (float): focusing parameter (default=2.0)\n                      higher gamma focuses more on hard examples\n        alpha (float): weighting factor for class imbalance (default=0.25)\n                      balances positive/negative examples importance\n\n    returns:\n        function: focal loss function ready for use in model compilation\n\n    \n\n    note:\n        reduces loss contribution from easily classified examples\n        helps when class imbalance is extreme (e.g., 1:100 ratio)\n        combines well with class weights for doubly-robust imbalance handling\n    \"\"\"\n    def focal_loss_fixed(y_true, y_pred):\n        y_true = tf.cast(y_true, tf.float32)\n        y_pred = tf.clip_by_value(y_pred, K.epsilon(), 1. - K.epsilon())\n        pt_1 = tf.where(tf.equal(y_true, 1), y_pred, tf.ones_like(y_pred))\n        pt_0 = tf.where(tf.equal(y_true, 0), 1. - y_pred, tf.ones_like(y_pred))\n        loss = -K.mean(alpha * K.pow(1. - pt_1, gamma) * K.log(pt_1) + \\\n                       (1 - alpha) * K.pow(1. - pt_0, gamma) * K.log(pt_0))\n        return loss\n    return focal_loss_fixed","metadata":{"trusted":true,"execution":{"execution_failed":"2025-05-15T09:00:30.085Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Enhanced CNN model with more layers and both ReLU/Swish options\ndef create_custom_cnn(img_size=224, activation='relu'):\n    \n    \"\"\"\n    creates an enhanced custom cnn model with flexible activation functions.\n    the model features:\n    4 convolutional blocks with increasing filters\n    batch normalization after each conv layer\n    spatial dropout for better regularization\n    optional swish activation (alternative to relu)\n    focal loss for handling class imbalance\n    \n    args:\n        img_size (int): input image dimensions (default 224x224)\n        activation (str): activation function to use ('relu' or 'swish', default 'relu')\n    \n    returns:\n        tensorflow.keras.models.Sequential: compiled cnn model ready for training\n    \n    architecture details:\n        block 1: 32 filters, spatial dropout 0.2\n        block 2: 64 filters, spatial dropout 0.3\n        block 3: 128 filters, spatial dropout 0.4\n        block 4: 256 filters, spatial dropout 0.5\n        dense layers: 512 and 256 units with 0.5 dropout\n        output: single sigmoid unit for binary classification\n    \"\"\"\n    \n    \n        \"\"\"\n        swish activation function: x * sigmoid(x)\n        provides non-monotonic \"bump\" that helps with gradient flow\n        \"\"\"\n    def swish(x):\n        return x * K.sigmoid(x)\n    \n    # Register Swish as a custom activation\n    tf.keras.utils.get_custom_objects().update({'swish': Activation(swish)})\n    \n    model = Sequential(name=f\"Enhanced_CNN_{activation}\")\n    \n    # Determine activation function to use\n    if activation == 'swish':\n        act_func = swish\n    else:  # Default to ReLU\n        act_func = 'relu'\n    \n  \n    \"\"\"\n    block 1: initial feature extraction\n    two 3x3 conv layers with 32 filters\n    batch norm for stable training\n    max pooling for dimensionality reduction\n    spatial dropout (more effective than regular dropout for conv layers)\n    \"\"\"\n    model.add(Conv2D(32, (3, 3), padding='same', input_shape=(img_size, img_size, 3)))\n    model.add(Activation(act_func))\n    model.add(BatchNormalization())\n    model.add(Conv2D(32, (3, 3), padding='same'))\n    model.add(Activation(act_func))\n    model.add(BatchNormalization())\n    model.add(MaxPooling2D(pool_size=(2, 2)))\n    model.add(SpatialDropout2D(0.2))\n    \n    \"\"\"\n    block 2: intermediate feature learning\n    increased to 64 filters\n    higher spatial dropout (0.3)\n    same structure as block 1\n    \"\"\"\n    model.add(Conv2D(64, (3, 3), padding='same'))\n    model.add(Activation(act_func))\n    model.add(BatchNormalization())\n    model.add(Conv2D(64, (3, 3), padding='same'))\n    model.add(Activation(act_func))\n    model.add(BatchNormalization())\n    model.add(MaxPooling2D(pool_size=(2, 2)))\n    model.add(SpatialDropout2D(0.3))\n    \n    \"\"\"\n    block 3: higher-level feature extraction\n    128 filters for more complex patterns\n    increased spatial dropout (0.4)\n    \"\"\"\n    model.add(Conv2D(128, (3, 3), padding='same'))\n    model.add(Activation(act_func))\n    model.add(BatchNormalization())\n    model.add(Conv2D(128, (3, 3), padding='same'))\n    model.add(Activation(act_func))\n    model.add(BatchNormalization())\n    model.add(MaxPooling2D(pool_size=(2, 2)))\n    model.add(SpatialDropout2D(0.4))\n    \n    \"\"\"\n    block 4: final convolutional block\n    256 filters for most complex features\n    highest spatial dropout (0.5)\n    \"\"\"\n    model.add(Conv2D(256, (3, 3), padding='same'))\n    model.add(Activation(act_func))\n    model.add(BatchNormalization())\n    model.add(Conv2D(256, (3, 3), padding='same'))\n    model.add(Activation(act_func))\n    model.add(BatchNormalization())\n    model.add(MaxPooling2D(pool_size=(2, 2)))\n    model.add(SpatialDropout2D(0.5))\n    \n     \"\"\"\n    block 4: final convolutional block\n     256 filters for most complex features\n     highest spatial dropout (0.5)\n    \"\"\"\n    model.add(Flatten())\n    model.add(Dense(512))\n    model.add(Activation(act_func))\n    model.add(BatchNormalization())\n    model.add(Dropout(0.5))\n    \n    model.add(Dense(256))\n    model.add(Activation(act_func))\n    model.add(BatchNormalization())\n    model.add(Dropout(0.5))\n    \n    model.add(Dense(1, activation='sigmoid'))\n\n\n     \"\"\"\n    model compilation:\n     adam optimizer with low learning rate (1e-4)\n     focal loss for class imbalance\n     multiple metrics: accuracy, auc, precision, recall\n    \"\"\"\n    optimizer = tf.keras.optimizers.Adam(learning_rate=1e-4)\n    model.compile(\n        optimizer=optimizer,\n        loss=focal_loss(gamma=2, alpha=0.25),\n        metrics=[\n            'accuracy',\n            tf.keras.metrics.AUC(name='auc'),\n            tf.keras.metrics.Precision(name='precision'),\n            tf.keras.metrics.Recall(name='recall')\n        ]\n    )\n    print(f\"Enhanced CNN with {activation} activation created.\")\n    model.summary()\n    return model","metadata":{"trusted":true,"execution":{"execution_failed":"2025-05-15T09:00:30.085Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 6. Pre-trained VGG16 Model\ndef create_pretrained_vgg16(img_size=224):\n    \"\"\"\n    creates a pneumonia classifier using transfer learning with vgg16.\n    leverages imagenet-pretrained weights for feature extraction with a custom classification head.\n    \n    args:\n        img_size (int): input image dimensions (default 224x224 - must match vgg16's expected size)\n    \n    returns:\n        tuple: (full_model, base_model)\n            full_model: compiled keras model ready for training\n            base_model: original vgg16 model (frozen)\n    \n    model architecture:\n         frozen vgg16 base (convolutional layers only)\n         global average pooling\n         dense layer (512 units, relu)\n         50% dropout\n         sigmoid output layer\n    \n    training approach:\n        base model weights remain frozen (not trainable)\n        only custom head layers are trained\n        uses focal loss to handle class imbalance\n        low learning rate (1e-4) for gentle fine-tuning\n    \"\"\"\n    \n    \"\"\"\n    load pre-trained vgg16 model:\n        weights: imagenet (pre-trained on large image dataset)\n        include_top: false (we replace the original classification head)\n        input_shape: must match our image size (224x224 is vgg16's default)\n    \"\"\"\n    base_model = VGG16(\n        weights='imagenet',\n        include_top=False,\n        input_shape=(img_size, img_size, 3)\n    )\n    base_model.trainable = False\n    print(f\"Loaded VGG16 with {len(base_model.layers)} layers. Base model frozen.\")\n    \"\"\"\n    build custom classification head:\n         global average pooling reduces spatial dimensions\n         dense layer with relu activation\n         dropout for regularization\n         final sigmoid output for binary classification\n    \"\"\"\n    x = base_model.output\n    x = GlobalAveragePooling2D()(x)\n    x = Dense(512, activation='relu')(x)\n    x = Dropout(0.5)(x)\n    predictions = Dense(1, activation='sigmoid')(x)\n    model = Model(inputs=base_model.input, outputs=predictions, name=\"VGG16_Transfer\")\n\n    \"\"\"\n    compile model with:\n         adam optimizer (low learning rate 1e-4)\n         focal loss (gamma=2, alpha=0.25)\n         comprehensive metrics:\n             accuracy\n             auc (area under roc curve)\n             precision\n             recall\n    \"\"\"\n    optimizer = tf.keras.optimizers.Adam(learning_rate=1e-4)\n    model.compile(\n        optimizer=optimizer,\n        loss=focal_loss(gamma=2, alpha=0.25),\n        metrics=[\n            'accuracy',\n            tf.keras.metrics.AUC(name='auc'),\n            tf.keras.metrics.Precision(name='precision'),\n            tf.keras.metrics.Recall(name='recall')\n        ]\n    )\n    print(\"VGG16 model with custom head created.\")\n    model.summary()\n    return model, base_model","metadata":{"trusted":true,"execution":{"execution_failed":"2025-05-15T09:00:30.086Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 7. Model Training and Fine-tuning\ndef train_model(model, train_gen, val_gen, class_weights, epochs=200, model_name='model'):\n    \"\"\"Train model with callbacks\"\"\"\n    print(f\"\\n--- Starting Training: {model_name} ---\")\n    callbacks = [\n        EarlyStopping(monitor='val_auc', patience=7, restore_best_weights=True, mode='max', verbose=1),\n        ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=3, min_lr=1e-6, verbose=1),\n        ModelCheckpoint(f'best_{model_name}.keras', monitor='val_auc', save_best_only=True, mode='max', verbose=0)\n    ]\n    history = model.fit(\n        train_gen,\n        epochs=epochs,\n        validation_data=val_gen,\n        callbacks=callbacks,\n        class_weight=class_weights,\n        steps_per_epoch=train_gen.samples // train_gen.batch_size,\n        validation_steps=val_gen.samples // val_gen.batch_size\n    )\n    print(f\"--- Finished Training: {model_name} ---\")\n    return history","metadata":{"trusted":true,"execution":{"execution_failed":"2025-05-15T09:00:30.086Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def fine_tune_model(model, base_model, train_gen, val_gen, class_weights, epochs=50, model_name='model'):\n    \n    \"\"\"\n    trains a keras model with comprehensive callbacks and class weighting.\n    implements early stopping, learning rate reduction, and model checkpointing.\n    \n    args:\n        model (keras.Model): compiled model to train\n        train_gen (ImageDataGenerator): training data generator\n        val_gen (ImageDataGenerator): validation data generator\n        class_weights (dict): dictionary of class weights for imbalanced data\n        epochs (int): maximum number of training epochs (default 200)\n        model_name (str): identifier for saving model files (default 'model')\n    \n    returns:\n        keras.History: training history object containing metrics\n    \n    training strategy:\n        early stopping based on validation auc (patience=7)\n        learning rate reduction when validation loss plateaus (factor=0.2)\n        saves best model based on validation auc\n        uses class weights to handle imbalanced data\n        calculates proper steps per epoch based on dataset size\n    \n    callbacks:\n        earlystopping: stops training when val_auc doesn't improve for 7 epochs\n        reducelronplateau: reduces lr by factor of 0.2 when val_loss plateaus\n        modelcheckpoint: saves best model based on val_auc\n    \"\"\"\n    print(f\"\\n--- Starting Fine-tuning: {model_name} ---\")\n    base_model.trainable = True\n    fine_tune_at = 15\n    for layer in base_model.layers[:fine_tune_at]:\n        layer.trainable = False\n    print(f\"Unfreezing layers from index {fine_tune_at} onwards for fine-tuning.\")\n    optimizer = tf.keras.optimizers.Adam(learning_rate=1e-5)\n    model.compile(\n        optimizer=optimizer,\n        loss=focal_loss(gamma=2, alpha=0.25),\n        metrics=[\n            'accuracy',\n            tf.keras.metrics.AUC(name='auc'),\n            tf.keras.metrics.Precision(name='precision'),\n            tf.keras.metrics.Recall(name='recall')\n        ]\n    )\n    model.summary()\n    callbacks_fine = [\n        EarlyStopping(monitor='val_auc', patience=5, restore_best_weights=True, mode='max', verbose=1),\n        ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=3, min_lr=1e-7, verbose=1),\n        ModelCheckpoint(f'best_{model_name}_finetuned.keras', monitor='val_auc', save_best_only=True, mode='max', verbose=0)\n    ]\n    \"\"\"\n    execute model training:\n         uses class weights for imbalanced data\n         calculates proper steps per epoch\n         validates on validation set\n         applies all configured callbacks\n    \"\"\"\n    history_fine = model.fit(\n        train_gen,\n        epochs=epochs,\n        validation_data=val_gen,\n        callbacks=callbacks_fine,\n        class_weight=class_weights,\n        steps_per_epoch=train_gen.samples // train_gen.batch_size,\n        validation_steps=val_gen.samples // val_gen.batch_size\n    )\n    print(f\"--- Finished Fine-tuning: {model_name} ---\")\n    return history_fine","metadata":{"trusted":true,"execution":{"execution_failed":"2025-05-15T09:00:30.086Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 8. Model Evaluation\ndef evaluate_model(model, test_gen, model_name='model'):\n    \"\"\"Evaluate model performance with various metrics\"\"\"\n    print(f\"\\n--- Evaluating Model: {model_name} ---\")\n    predictions = model.predict(test_gen, steps=test_gen.samples // test_gen.batch_size + 1, verbose=1)\n    true_classes = test_gen.classes\n    predictions = predictions[:len(true_classes)]\n\n    print(\"\\nEvaluation with default threshold (0.5):\")\n    pred_classes_05 = (predictions > 0.5).astype(int).flatten()\n    print(classification_report(true_classes, pred_classes_05, target_names=['NORMAL', 'PNEUMONIA'], digits=3))\n    cm_05 = confusion_matrix(true_classes, pred_classes_05)\n    plt.figure(figsize=(7, 5))\n    sns.heatmap(cm_05, annot=True, fmt='d', cmap='Blues', xticklabels=['NORMAL', 'PNEUMONIA'], yticklabels=['NORMAL', 'PNEUMONIA'])\n    plt.title(f'Confusion Matrix - {model_name} (Threshold=0.5)')\n    plt.ylabel('True Label')\n    plt.xlabel('Predicted Label')\n    plt.tight_layout()\n    plt.savefig(f'{model_name}_confusion_matrix_0.5.png')\n    plt.show()\n\n    best_threshold, optimized_preds, best_f1 = optimize_threshold(true_classes, predictions)\n    print(f\"\\nEvaluation with optimized threshold ({best_threshold:.3f} for best F1={best_f1:.3f}):\")\n    print(classification_report(true_classes, optimized_preds, target_names=['NORMAL', 'PNEUMONIA'], digits=3))\n    cm_opt = confusion_matrix(true_classes, optimized_preds)\n    plt.figure(figsize=(7, 5))\n    sns.heatmap(cm_opt, annot=True, fmt='d', cmap='Oranges', xticklabels=['NORMAL', 'PNEUMONIA'], yticklabels=['NORMAL', 'PNEUMONIA'])\n    plt.title(f'Confusion Matrix - {model_name} (Opt Threshold={best_threshold:.3f})')\n    plt.ylabel('True Label')\n    plt.xlabel('Predicted Label')\n    plt.tight_layout()\n    plt.savefig(f'{model_name}_confusion_matrix_optimized.png')\n    plt.show()\n\n    fpr, tpr, _ = roc_curve(true_classes, predictions)\n    roc_auc = auc(fpr, tpr)\n    plt.figure(figsize=(8, 6))\n    plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (AUC = {roc_auc:.3f})')\n    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n    plt.xlabel('False Positive Rate')\n    plt.ylabel('True Positive Rate')\n    plt.title(f'ROC Curve - {model_name}')\n    plt.legend(loc='lower right')\n    plt.grid(alpha=0.3)\n    plt.savefig(f'{model_name}_roc_curve.png')\n    plt.show()\n\n    precision, recall, _ = precision_recall_curve(true_classes, predictions)\n    average_precision = average_precision_score(true_classes, predictions)\n    plt.figure(figsize=(8, 6))\n    plt.plot(recall, precision, color='blue', lw=2, label=f'PR curve (AP = {average_precision:.3f})')\n    plt.xlabel('Recall')\n    plt.ylabel('Precision')\n    plt.title(f'Precision-Recall Curve - {model_name}')\n    plt.legend(loc='lower left')\n    plt.grid(alpha=0.3)\n    plt.savefig(f'{model_name}_pr_curve.png')\n    plt.show()\n\n    final_accuracy = (optimized_preds == true_classes).mean()\n    final_f1 = f1_score(true_classes, optimized_preds)\n    print(f\"Metrics Summary ({model_name}):\")\n    print(f\"  AUC: {roc_auc:.4f}\")\n    print(f\"  Average Precision (AP): {average_precision:.4f}\")\n    print(f\"  Accuracy (Optimized Threshold): {final_accuracy:.4f}\")\n    print(f\"  F1 Score (Optimized Threshold): {final_f1:.4f}\")\n\n    return {\n        'predictions': predictions,\n        'true_classes': true_classes,\n        'pred_classes_0.5': pred_classes_05,\n        'optimized_preds': optimized_preds,\n        'best_threshold': best_threshold,\n        'metrics': {'accuracy': final_accuracy, 'auc': roc_auc, 'average_precision': average_precision, 'f1': final_f1}\n    }","metadata":{"trusted":true,"execution":{"execution_failed":"2025-05-15T09:00:30.086Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def optimize_threshold(true_classes, predictions):\n    \"\"\"Find optimal threshold for F1 score\"\"\"\n    best_f1 = 0\n    best_threshold = 0.5\n    thresholds = np.arange(0.1, 0.9, 0.01)\n    f1_scores = []\n    for threshold in thresholds:\n        pred_classes = (predictions >= threshold).astype(int).flatten()\n        f1 = f1_score(true_classes, pred_classes)\n        f1_scores.append(f1)\n        if f1 > best_f1:\n            best_f1 = f1\n            best_threshold = threshold\n    print(f\"Optimal threshold found: {best_threshold:.3f} with F1 score: {best_f1:.4f}\")\n    plt.figure(figsize=(8, 5))\n    plt.plot(thresholds, f1_scores)\n    plt.title('F1 Score vs. Threshold')\n    plt.xlabel('Threshold')\n    plt.ylabel('F1 Score')\n    plt.vlines(best_threshold, 0, best_f1, colors='r', linestyles='--', label=f'Best Threshold ({best_threshold:.3f})')\n    plt.legend()\n    plt.grid(alpha=0.3)\n    plt.savefig('f1_vs_threshold.png')\n    plt.show()\n    optimized_preds = (predictions >= best_threshold).astype(int).flatten()\n    return best_threshold, optimized_preds, best_f1","metadata":{"trusted":true,"execution":{"execution_failed":"2025-05-15T09:00:30.086Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 9. Ensemble Model\ndef create_ensemble(models_dict, test_gen):\n    \"\"\"Create an ensemble of models by averaging predictions\"\"\"\n    print(\"\\n--- Creating Ensemble ---\")\n    all_predictions = []\n    model_names = list(models_dict.keys())\n    if len(model_names) < 2:\n        print(\"Need at least two models to create an ensemble. Skipping.\")\n        return None, None\n    print(f\"Ensembling models: {model_names}\")\n    for model_name, model in models_dict.items():\n        print(f\"Getting predictions from {model_name}...\")\n        preds = model.predict(test_gen, steps=test_gen.samples // test_gen.batch_size + 1, verbose=0)\n        true_classes = test_gen.classes\n        preds = preds[:len(true_classes)]\n        all_predictions.append(preds)\n    if not all_predictions:\n        print(\"No predictions generated for ensemble. Skipping.\")\n        return None, None\n    ensemble_preds = np.mean(all_predictions, axis=0)\n    print(\"Ensemble predictions generated.\")\n    return ensemble_preds, true_classes\n","metadata":{"trusted":true,"execution":{"execution_failed":"2025-05-15T09:00:30.086Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 10. Explainable AI (XAI) Techniques\ndef get_gradcam(model, img_array, last_conv_layer_name, pred_index=None):\n    \"\"\"Generate Grad-CAM heatmap\"\"\"\n    try:\n        grad_model = tf.keras.models.Model(\n            [model.inputs],\n            [model.get_layer(last_conv_layer_name).output, model.output]\n        )\n    except ValueError as e:\n        print(f\"Error creating Grad-CAM model: {e}\")\n        print(f\"Ensure '{last_conv_layer_name}' is a valid convolutional layer name in the model.\")\n        print(\"Available layer names:\")\n        for layer in model.layers: print(f\"  - {layer.name} (Type: {type(layer).__name__})\")\n        return None\n    with tf.GradientTape() as tape:\n        last_conv_layer_output, preds = grad_model(img_array)\n        if pred_index is None: pred_index = tf.argmax(preds[0])\n        class_output = preds[:, 0]\n    grads = tape.gradient(class_output, last_conv_layer_output)\n    if grads is None:\n        print(\"Grad-CAM: Gradients are None. Check model structure and layer connectivity.\")\n        return None\n    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n    last_conv_layer_output = last_conv_layer_output[0]\n    heatmap = last_conv_layer_output @ pooled_grads[..., tf.newaxis]\n    heatmap = tf.squeeze(heatmap)\n    heatmap = tf.maximum(heatmap, 0) / (tf.math.reduce_max(heatmap) + K.epsilon())\n    return heatmap.numpy()\n\ndef visualize_gradcam(img, heatmap, alpha=0.5, title=\"Grad-CAM\"):\n    \"\"\"Visualize Grad-CAM heatmap overlaid on original image\"\"\"\n    if heatmap is None:\n        print(\"Cannot visualize Grad-CAM: Heatmap is None.\")\n        return\n    if img.dtype == np.float32 or img.dtype == np.float64: img = (img * 255).astype(np.uint8)\n    if len(img.shape) == 2: img = cv2.cvtColor(img, cv2.COLOR_GRAY2RGB)\n    elif len(img.shape) == 3 and img.shape[2] == 1: img = cv2.cvtColor(img, cv2.COLOR_GRAY2RGB)\n    heatmap = cv2.resize(heatmap, (img.shape[1], img.shape[0]))\n    heatmap = np.uint8(255 * heatmap)\n    heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)\n    superimposed_img = cv2.addWeighted(img, 1 - alpha, heatmap, alpha, 0)\n    plt.figure(figsize=(12, 4))\n    plt.subplot(1, 3, 1); plt.imshow(img); plt.title('Original Image'); plt.axis('off')\n    plt.subplot(1, 3, 2); plt.imshow(heatmap); plt.title('Heatmap'); plt.axis('off')\n    plt.subplot(1, 3, 3); plt.imshow(superimposed_img); plt.title(title); plt.axis('off')\n    plt.tight_layout()\n    plt.savefig(f'{title.replace(\" \", \"_\").lower()}_gradcam.png')\n    plt.show()\n    return superimposed_img\n\ndef explain_with_lime(model, img_array, num_samples=500):\n    \"\"\"Generate LIME explanation\"\"\"\n    print(\"Generating LIME explanation...\")\n    image_for_lime = img_array[0]\n    explainer = lime_image.LimeImageExplainer()\n    def predict_fn_lime(images):\n        processed_images = []\n        for img in images:\n            if img.dtype == np.uint8: img = img.astype('float32') / 255.0\n            processed_images.append(img)\n        processed_images = np.array(processed_images)\n        if len(processed_images.shape) == 3: processed_images = np.expand_dims(processed_images, axis=0)\n        return model.predict(processed_images)\n    try:\n        explanation = explainer.explain_instance(\n            image_for_lime.astype('double'),\n            predict_fn_lime,\n            top_labels=1,\n            hide_color=0,\n            num_samples=num_samples\n        )\n        temp, mask = explanation.get_image_and_mask(\n            explanation.top_labels[0], positive_only=False, num_features=10, hide_rest=False\n        )\n        plt.figure(figsize=(8, 4))\n        plt.subplot(1, 2, 1)\n        display_img = image_for_lime if image_for_lime.dtype != np.uint8 else (image_for_lime / 255.0)\n        plt.imshow(display_img); plt.title('Original Image'); plt.axis('off')\n        plt.subplot(1, 2, 2)\n        plt.imshow(mark_boundaries(temp / 2 + 0.5, mask)); plt.title('LIME Explanation'); plt.axis('off')\n        plt.tight_layout()\n        plt.savefig('lime_explanation.png')\n        plt.show()\n        print(\"LIME explanation generated.\")\n        return explanation\n    except Exception as e:\n        print(f\"Error during LIME explanation: {e}\")\n        return None","metadata":{"trusted":true,"execution":{"execution_failed":"2025-05-15T09:00:30.086Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 11. Compare Different Models\ndef compare_models(results_dict):\n    \"\"\"Compare performance of different models based on evaluation results\"\"\"\n    print(\"\\n--- Comparing Model Performance ---\")\n    models = list(results_dict.keys())\n    if not models:\n        print(\"No results to compare.\")\n        return None\n    accuracy = [results_dict[model]['metrics']['accuracy'] for model in models]\n    auc_scores = [results_dict[model]['metrics']['auc'] for model in models] # Renamed to avoid conflict with auc function\n    ap = [results_dict[model]['metrics']['average_precision'] for model in models]\n    f1 = [results_dict[model]['metrics']['f1'] for model in models]\n\n    plt.figure(figsize=(14, 10))\n    bar_width = 0.6\n    plt.subplot(2, 2, 1); plt.bar(models, accuracy, color='skyblue', width=bar_width); plt.title('Accuracy Comparison (Optimized Threshold)'); plt.ylabel('Accuracy'); plt.ylim(0, 1); plt.xticks(rotation=15, ha='right'); plt.grid(axis='y', alpha=0.3)\n    plt.subplot(2, 2, 2); plt.bar(models, auc_scores, color='salmon', width=bar_width); plt.title('AUC Comparison'); plt.ylabel('AUC'); plt.ylim(0, 1); plt.xticks(rotation=15, ha='right'); plt.grid(axis='y', alpha=0.3)\n    plt.subplot(2, 2, 3); plt.bar(models, ap, color='lightgreen', width=bar_width); plt.title('Average Precision Comparison'); plt.ylabel('Average Precision (AP)'); plt.ylim(0, 1); plt.xticks(rotation=15, ha='right'); plt.grid(axis='y', alpha=0.3)\n    plt.subplot(2, 2, 4); plt.bar(models, f1, color='mediumpurple', width=bar_width); plt.title('F1 Score Comparison (Optimized Threshold)'); plt.ylabel('F1 Score'); plt.ylim(0, 1); plt.xticks(rotation=15, ha='right'); plt.grid(axis='y', alpha=0.3)\n    plt.tight_layout(pad=2.0)\n    plt.savefig('model_comparison.png')\n    plt.show()\n\n    summary = pd.DataFrame({'Model': models, 'Accuracy': accuracy, 'AUC': auc_scores, 'Avg Precision': ap, 'F1 Score': f1}).round(4)\n    print(\"\\nModel Performance Summary:\")\n    print(summary.sort_values('F1 Score', ascending=False).to_string(index=False))\n    best_model_name = summary.loc[summary['F1 Score'].idxmax()]['Model'] if not summary.empty else None\n    if best_model_name: print(f\"\\nBest model based on F1 Score: {best_model_name}\")\n    return summary, best_model_name\n","metadata":{"trusted":true,"execution":{"execution_failed":"2025-05-15T09:00:30.086Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def plot_training_history(history, model_plot_name):\n    \"\"\"Plots training and validation metrics from Keras history.\"\"\"\n    if not history or not history.history:\n        print(f\"No history data to plot for {model_plot_name}.\")\n        return\n\n    history_df = pd.DataFrame(history.history)\n\n    plt.figure(figsize=(18, 12))\n\n    # Plot Loss\n    plt.subplot(2, 2, 1)\n    if 'loss' in history_df:\n        plt.plot(history_df['loss'], label='Training Loss')\n    if 'val_loss' in history_df:\n        plt.plot(history_df['val_loss'], label='Validation Loss')\n    plt.title(f'Loss vs. Epochs - {model_plot_name}')\n    plt.xlabel('Epochs')\n    plt.ylabel('Loss')\n    if 'loss' in history_df or 'val_loss' in history_df:\n        plt.legend()\n    plt.grid(True, alpha=0.3)\n\n    # Plot Accuracy\n    plt.subplot(2, 2, 2)\n    if 'accuracy' in history_df:\n        plt.plot(history_df['accuracy'], label='Training Accuracy')\n    if 'val_accuracy' in history_df:\n        plt.plot(history_df['val_accuracy'], label='Validation Accuracy')\n    plt.title(f'Accuracy vs. Epochs - {model_plot_name}')\n    plt.xlabel('Epochs')\n    plt.ylabel('Accuracy')\n    if 'accuracy' in history_df or 'val_accuracy' in history_df:\n        plt.legend()\n    plt.grid(True, alpha=0.3)\n\n    # Plot AUC\n    plt.subplot(2, 2, 3)\n    if 'auc' in history_df:\n        plt.plot(history_df['auc'], label='Training AUC')\n    if 'val_auc' in history_df:\n        plt.plot(history_df['val_auc'], label='Validation AUC')\n    plt.title(f'AUC vs. Epochs - {model_plot_name}')\n    plt.xlabel('Epochs')\n    plt.ylabel('AUC')\n    if 'auc' in history_df or 'val_auc' in history_df:\n        plt.legend()\n    plt.grid(True, alpha=0.3)\n\n    # Plot Precision and Recall\n    plt.subplot(2, 2, 4)\n    legend_items = []\n    if 'precision' in history_df:\n        plt.plot(history_df['precision'], label='Training Precision')\n        legend_items.append('Training Precision')\n    if 'val_precision' in history_df:\n        plt.plot(history_df['val_precision'], label='Validation Precision')\n        legend_items.append('Validation Precision')\n    if 'recall' in history_df:\n        plt.plot(history_df['recall'], label='Training Recall', linestyle='--')\n        legend_items.append('Training Recall')\n    if 'val_recall' in history_df:\n        plt.plot(history_df['val_recall'], label='Validation Recall', linestyle='--')\n        legend_items.append('Validation Recall')\n\n    plt.title(f'Precision & Recall vs. Epochs - {model_plot_name}')\n    plt.xlabel('Epochs')\n    plt.ylabel('Metric Value')\n    if legend_items: # Only show legend if there's something to show\n        plt.legend()\n    plt.grid(True, alpha=0.3)\n\n    plt.tight_layout()\n    plt.savefig(f'{model_plot_name}_training_history.png')\n    plt.show()\n    print(f\"Training history plots saved for {model_plot_name}.\")","metadata":{"trusted":true,"execution":{"execution_failed":"2025-05-15T09:00:30.087Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def main():\n    \"\"\"Main function to run the complete pipeline\"\"\"\n    print(\"--- Starting Pneumonia Prediction Project ---\")\n\n    print(\"\\n=== Step 1: Exploring Dataset ===\")\n    try:\n        dataset_info = explore_dataset()\n    except Exception as e:\n        print(f\"Failed during dataset exploration: {e}\")\n        return\n\n    print(\"\\n=== Step 2: Creating Data Generators ===\")\n    img_size = 224\n    batch_size = 32\n    try:\n        # train_gen, val_gen, test_gen = create_data_generators(img_size, batch_size)\n        train_gen, val_gen, test_gen = create_data_generators(img_size, batch_size, validation_split=0.2)\n    except Exception as e:\n        print(f\"Failed to create data generators: {e}\")\n        return\n\n    print(\"\\n=== Step 3: Calculating Class Weights ===\")\n    class_weights = calculate_class_weights(dataset_info)\n    if train_gen.class_indices.get('NORMAL', -1) != 0 or train_gen.class_indices.get('PNEUMONIA', -1) != 1:\n        print(\"Warning: Class indices might not match expected {0: Normal, 1: Pneumonia}. Ensure class_weights dict is correct.\")\n        print(f\"Actual class indices: {train_gen.class_indices}\")\n\n\n    print(\"\\n=== Step 4: Creating and Training Models ===\")\n    all_results = {}\n    trained_models = {}\n\n    activation_functions = ['relu', 'swish']\n    for activation in activation_functions:\n        model_id = f'CNN_{activation}'\n        print(f\"\\n--- Training {model_id} ---\")\n        try:\n            model = create_custom_cnn(img_size, activation)\n            history = train_model(model, train_gen, val_gen, class_weights, epochs=200, model_name=f'cnn_{activation}')\n            plot_training_history(history, model_id) # ADDED PLOT CALL\n            model.load_weights(f'best_cnn_{activation}.keras')\n            results = evaluate_model(model, test_gen, model_name=model_id)\n            all_results[model_id] = results\n            trained_models[model_id] = model\n        except Exception as e:\n            print(f\"!!! Failed to train/evaluate {model_id}: {e}\")\n            import traceback; traceback.print_exc()\n\n    model_id_vgg = 'Pretrained_VGG16'\n    print(f\"\\n--- Training {model_id_vgg} ---\")\n    try:\n        model_vgg, base_model_vgg = create_pretrained_vgg16(img_size)\n        history_vgg = train_model(model_vgg, train_gen, val_gen, class_weights, epochs=100, model_name='vgg16_transfer')\n        plot_training_history(history_vgg, f'{model_id_vgg}_initial_transfer') # ADDED PLOT CALL\n        model_vgg.load_weights('best_vgg16_transfer.keras')\n        print(\"Loaded best weights from initial VGG16 training.\")\n\n        history_vgg_fine = fine_tune_model(model_vgg, base_model_vgg, train_gen, val_gen, class_weights, epochs=50, model_name='vgg16')\n        plot_training_history(history_vgg_fine, f'{model_id_vgg}_fine_tuning') # ADDED PLOT CALL\n\n        fine_tuned_path = 'best_vgg16_finetuned.keras'\n        transfer_path = 'best_vgg16_transfer.keras'\n        if os.path.exists(fine_tuned_path):\n             print(f\"Loading best fine-tuned weights from: {fine_tuned_path}\")\n             model_vgg.load_weights(fine_tuned_path)\n        elif os.path.exists(transfer_path): # Fallback to transfer weights if fine-tuned didn't improve or save\n             print(f\"Fine-tuned model checkpoint not found or did not improve. Loading best transfer weights from: {transfer_path}\")\n             model_vgg.load_weights(transfer_path)\n        else:\n             print(\"Warning: No saved weights found for VGG16. Evaluating with current weights.\")\n\n        results_vgg = evaluate_model(model_vgg, test_gen, model_name=model_id_vgg)\n        all_results[model_id_vgg] = results_vgg\n        trained_models[model_id_vgg] = model_vgg\n    except Exception as e:\n        print(f\"!!! Failed to train/evaluate {model_id_vgg}: {e}\")\n        import traceback; traceback.print_exc()\n\n    print(\"\\n=== Step 5: Creating and Evaluating Ensemble Model ===\")\n    ensemble_candidates = {}\n    if 'CNN_swish' in trained_models: ensemble_candidates['CNN_swish'] = trained_models['CNN_swish']\n    if 'Pretrained_VGG16' in trained_models: ensemble_candidates['Pretrained_VGG16'] = trained_models['Pretrained_VGG16']\n\n    if len(ensemble_candidates) >= 2:\n        try:\n            ensemble_preds, ensemble_true_classes = create_ensemble(ensemble_candidates, test_gen)\n            if ensemble_preds is not None:\n                print(\"\\n--- Evaluating Ensemble Model ---\")\n                ens_best_threshold, ens_optimized_preds, ens_best_f1 = optimize_threshold(ensemble_true_classes, ensemble_preds)\n                print(f\"\\nEnsemble Evaluation with optimized threshold ({ens_best_threshold:.3f}):\")\n                print(classification_report(ensemble_true_classes, ens_optimized_preds, target_names=['NORMAL', 'PNEUMONIA'], digits=3))\n                ens_accuracy = (ens_optimized_preds == ensemble_true_classes).mean()\n                ens_auc = roc_auc_score(ensemble_true_classes, ensemble_preds)\n                ens_ap = average_precision_score(ensemble_true_classes, ensemble_preds)\n                ens_f1 = f1_score(ensemble_true_classes, ens_optimized_preds)\n                all_results['Ensemble'] = {\n                    'predictions': ensemble_preds, 'true_classes': ensemble_true_classes,\n                    'pred_classes_0.5': (ensemble_preds > 0.5).astype(int),\n                    'optimized_preds': ens_optimized_preds, 'best_threshold': ens_best_threshold,\n                    'metrics': {'accuracy': ens_accuracy, 'auc': ens_auc, 'average_precision': ens_ap, 'f1': ens_f1}\n                }\n                cm_ens = confusion_matrix(ensemble_true_classes, ens_optimized_preds)\n                plt.figure(figsize=(7, 5))\n                sns.heatmap(cm_ens, annot=True, fmt='d', cmap='Greens', xticklabels=['NORMAL', 'PNEUMONIA'], yticklabels=['NORMAL', 'PNEUMONIA'])\n                plt.title(f'Confusion Matrix - Ensemble (Opt Threshold={ens_best_threshold:.3f})')\n                plt.ylabel('True Label'); plt.xlabel('Predicted Label')\n                plt.tight_layout(); plt.savefig('ensemble_confusion_matrix_optimized.png'); plt.show()\n        except Exception as e:\n            print(f\"!!! Failed to create/evaluate ensemble model: {e}\")\n            import traceback; traceback.print_exc()\n    else:\n        print(\"Skipping ensemble: Not enough base models trained successfully.\")\n\n    print(\"\\n=== Step 6: Comparing All Models ===\")\n    model_comparison_summary, best_model_name = None, None \n    if all_results:\n        model_comparison_summary, best_model_name = compare_models(all_results)\n    else:\n        print(\"No models were successfully trained and evaluated. Cannot compare.\")\n\n    print(\"\\n=== Step 7: Applying XAI Techniques ===\")\n    if best_model_name and best_model_name != 'Ensemble' and best_model_name in trained_models:\n        print(f\"Applying XAI to the best individual model: {best_model_name}\")\n        best_model = trained_models[best_model_name]\n        test_gen.reset()\n        normal_img, pneumonia_img = None, None\n        try:\n            for i in range(len(test_gen)): # Iterate through batches\n                img_batch, label_batch = next(test_gen)\n                if normal_img is None and 0 in label_batch:\n                    normal_idx = np.where(label_batch == 0)[0][0]\n                    normal_img = img_batch[normal_idx:normal_idx+1]\n                    print(\"Found sample Normal image for XAI.\")\n                if pneumonia_img is None and 1 in label_batch:\n                    pneumonia_idx = np.where(label_batch == 1)[0][0]\n                    pneumonia_img = img_batch[pneumonia_idx:pneumonia_idx+1]\n                    print(\"Found sample Pneumonia image for XAI.\")\n                if normal_img is not None and pneumonia_img is not None: break\n            if normal_img is None or pneumonia_img is None: print(\"Warning: Could not find both Normal and Pneumonia samples in test set for XAI.\")\n        except Exception as e: print(f\"Error getting sample images for XAI: {e}\")\n\n        last_conv_layer_name = None\n        for layer in reversed(best_model.layers):\n            if isinstance(layer, (Conv2D, tf.keras.layers.SeparableConv2D)):\n                 is_in_base = any(layer.name == base_layer.name for base_layer in getattr(best_model, 'layers', []) if isinstance(base_layer, Model) and hasattr(base_layer, 'layers'))\n                 last_conv_layer_name = layer.name\n                 break\n        if not last_conv_layer_name:\n             print(\"Warning: Could not automatically find a Conv2D layer for Grad-CAM.\")\n             if 'VGG16' in best_model_name: last_conv_layer_name = 'block5_conv3' # VGG16 specific fallback\n\n        if last_conv_layer_name and normal_img is not None:\n            print(f\"\\nApplying Grad-CAM (layer: {last_conv_layer_name}) to Normal Image...\")\n            normal_heatmap = get_gradcam(best_model, normal_img, last_conv_layer_name)\n            visualize_gradcam(normal_img[0], normal_heatmap, title=f\"Grad-CAM Normal ({best_model_name})\")\n        if last_conv_layer_name and pneumonia_img is not None:\n            print(f\"\\nApplying Grad-CAM (layer: {last_conv_layer_name}) to Pneumonia Image...\")\n            pneumonia_heatmap = get_gradcam(best_model, pneumonia_img, last_conv_layer_name)\n            visualize_gradcam(pneumonia_img[0], pneumonia_heatmap, title=f\"Grad-CAM Pneumonia ({best_model_name})\")\n\n        if normal_img is not None: print(\"\\nApplying LIME to Normal Image...\"); explain_with_lime(best_model, normal_img)\n        if pneumonia_img is not None: print(\"\\nApplying LIME to Pneumonia Image...\"); explain_with_lime(best_model, pneumonia_img)\n\n        \n\n    print(\"\\n--- Project Pipeline Completed ---\")\n    if best_model_name and model_comparison_summary is not None and not model_comparison_summary.empty:\n        best_score_row = model_comparison_summary[model_comparison_summary['Model'] == best_model_name]\n        if not best_score_row.empty:\n             best_score = best_score_row['F1 Score'].iloc[0]\n             print(f\"Best Model Identified: {best_model_name} (F1 Score: {best_score:.4f})\")\n        else:\n            print(f\"Best model name '{best_model_name}' not found in summary. Check model IDs.\")\n    elif model_comparison_summary is not None and not model_comparison_summary.empty:\n        print(\"Review the performance summary table above for details on trained models.\")\n    else:\n        print(\"No models were successfully evaluated or no summary available.\")\n\nif __name__ == \"__main__\":\n    main()","metadata":{"trusted":true,"execution":{"execution_failed":"2025-05-15T09:00:30.087Z"}},"outputs":[],"execution_count":null}]}